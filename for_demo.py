import streamlit as st
import pandas as pd
import torch
from torch import nn
from torch.nn import Parameter

import random

import numpy as np


# å¯åŠ¨
# streamlit run for_demo.py --server.port=9002
markdown_code_1 = """
# AIæ¨¡å‹åˆ›å»ºåŠè®­ç»ƒâ€”â€”å…¥é—¨ç¯‡
## æ–¹ç¨‹æ±‚è§£
å‡è®¾æ±‚è§£æ–¹ç¨‹ï¼š$y = 3x + 1$ä¸­çš„å„ä¸ªç³»æ•°

ä¹Ÿå°±æ˜¯æ±‚è§£æ–¹ç¨‹ $y=ax+b$ ä¸­çš„$a,b$
"""
st.markdown(markdown_code_1)


code_1 = """
import pandas as pd
import numpy as np
import random

import torch
from torch import nn
from torch.nn import Parameter
from torch.autograd import Variable
import random
import matplotlib.pyplot as plt
import os
import math
import numpy as np
from tqdm import tqdm

"""

code_1a = """
point_num = 50
x = np.linspace(0, 10, point_num)
# æ•°æ®é›†æ·»åŠ æ‰°åŠ¨
y = [3*i+1 + random.random()*2 for i in x]
"""
with st.expander("å‡†å¤‡æ•°æ®"):
    st.code(code_1, language='python')

    st.code(code_1a, language='python')


point_num = st.slider("æ ·æœ¬çš„æ•°é‡", 10, 100, 50, key="point_num_1")

noise = st.slider("å™ªéŸ³", 0, 100, 2, key="noise_1")

scatter_size = st.slider("ç‚¹çš„å¤§å°", 1, 50, 20, key="scatter_size_1")

x = np.linspace(0, 10, point_num)
# æ•°æ®é›†æ·»åŠ æ‰°åŠ¨
y = [3*i + 1 + random.random()*noise for i in x]

st.scatter_chart(pd.DataFrame({"x": x, "y":y}), x="x", y="y", size=scatter_size)


code_2 = """
# åˆ›å»ºæ¨¡å‹
class DemoModel(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # å˜é‡
        self.a = Parameter(torch.tensor([1.]))
        self.b = Parameter(torch.tensor([2.]))
    
    def forward(self, x):
        return self.a * x+ self.b
model = DemoModel()
"""



# åˆ›å»ºæ¨¡å‹
class DemoModel(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # å˜é‡
        self.a = Parameter(torch.tensor([1.]))
        self.b = Parameter(torch.tensor([2.]))
    
    def forward(self, x):
        return self.a * x+ self.b


code_2a='''
# å°†æ•°æ®æ”¹ä¸ºbatchè¾“å‡º
def get_batch_data(data, batch_size, shuffle=True):
    """
    ç”Ÿæˆ batch æ•°æ®
    :param data: æ•°æ®é›†
    :param batch_size: batch å¤§å°
    :param shuffle: æ˜¯å¦æ‰“ä¹±
    :return:
    """
    data_size = len(data)
    num_batches = data_size // batch_size
    # æ˜¯å¦éœ€è¦æ‰“ä¹±æ•°æ®
    if shuffle:
        random.shuffle(data)
    out = []
    for i in range(num_batches):
        start = i * batch_size
        end = min(start + batch_size, data_size)
        batch_data = data[start:end]
        # æ‹†åˆ† x å’Œ y
        x_batch, y_batch = zip(*batch_data)
        out.append([list(x_batch), list(y_batch)])
    return out
'''




def get_batch_data(data, batch_size, shuffle=True):
    """
    ç”Ÿæˆ batch æ•°æ®
    :param data: æ•°æ®é›†
    :param batch_size: batch å¤§å°
    :param shuffle: æ˜¯å¦æ‰“ä¹±
    :return:
    """
    data_size = len(data)
    num_batches = data_size // batch_size
    # æ˜¯å¦éœ€è¦æ‰“ä¹±æ•°æ®
    if shuffle:
        random.shuffle(data)
    out = []
    for i in range(num_batches):
        start = i * batch_size
        end = min(start + batch_size, data_size)
        batch_data = data[start:end]
        # æ‹†åˆ† x å’Œ y
        x_batch, y_batch = zip(*batch_data)
        out.append([list(x_batch), list(y_batch)])
    return out


code_3 = """
optimizer = torch.optim.Adam(params=[p for n, p in model.named_parameters()], 
                             lr=0.001)

epochs = 40
for epoch in range(epochs):
    for d, t in get_batch_data(data, 20, True):
        out = model(torch.tensor([d]))
        loss = torch.mean(torch.pow(out-torch.tensor(t),2))
        # ä¼˜åŒ–å™¨æ¢¯åº¦æ¸…é™¤
        optimizer.zero_grad()
        # åå‘ä¼ æ’­
        loss.backward()
        # ä¼˜åŒ–æ›´æ–°
        optimizer.step()
        
"""

with st.expander("åˆ›å»ºæ¨¡å‹å¹¶è®­ç»ƒ"):
    st.code(code_2, language='python')
    st.code(code_2a, language='python')
    st.code(code_3, language='python')

batch_size = st.slider("batch", 1, 100, 20, key="batch_size")

# å­¦ä¹ ç‡
lr = st.select_slider('learning_rate',options=[5e-5, 5e-4, 0.01, 0.02, 0.1, 0.2, 0.4], value=0.01, key="lr")

# epoch
epochs = st.slider("epochs", 1, 200, 20, key="epochs")

# shuffle
shuffle = st.toggle('æ‰“ä¹±æ•°æ®é›†', value=True, key="shuffle")


model = DemoModel()
a_item = []
a_grad = []
loss_item = []
# ä¼˜åŒ–å™¨
optimizer = torch.optim.Adam(params=[p for n, p in model.named_parameters()], lr=lr)


progress_text = "training... Please wait."
training_bar = st.progress(0, text=progress_text)


data = list(zip(x, y))

for epoch in range(epochs):
    for d, t in get_batch_data(data, batch_size, shuffle):
        out = model(torch.tensor([d]))

        loss = torch.mean(torch.pow(out-torch.tensor(t),2))
        loss_item.append(loss.item())
        # ä¼˜åŒ–å™¨æ¢¯åº¦æ¸…é™¤
        optimizer.zero_grad()
        # åå‘ä¼ æ’­
        loss.backward()
        a_grad.append(model.a.grad.item())
        # ä¼˜åŒ–æ›´æ–°
        optimizer.step()
        a_item.append(model.a.item())
        
        training_bar.progress((epoch+1)/epochs, text=progress_text)
training_bar.empty()

st.line_chart(pd.DataFrame({"å˜é‡a": a_item}), y="å˜é‡a")
st.line_chart(pd.DataFrame({"å˜é‡aæ¢¯åº¦": a_grad}), y="å˜é‡aæ¢¯åº¦")
st.line_chart(pd.DataFrame({"æŸå¤±å€¼loss": loss_item}), y="æŸå¤±å€¼loss")



markdown_code_1 = """
## å¤æ‚æ–¹ç¨‹
é‚£ä¹ˆå¦‚ä½•æ‹Ÿåˆä¸€ä¸ªå‡½æ•°ï¼š$y = 3x^2 + 5$
"""

st.markdown(markdown_code_1)


code_5 = """
point_num = 50
x = np.linspace(0, 10, point_num)
# æ•°æ®é›†æ·»åŠ æ‰°åŠ¨
y = [3*i**2 + 5 + random.random()*2 for i in x]
"""
with st.expander("å‡†å¤‡æ•°æ®"):
    st.code(code_5, language='python')




point_num_2 = st.slider("æ ·æœ¬çš„æ•°é‡", 10, 100, 50, key="point_num_2")

noise_2 = st.slider("å™ªéŸ³", 0, 100, 2, key="noise_2")

scatter_size_2 = st.slider("ç‚¹çš„å¤§å°", 1, 50, 20, key="scatter_size_2")

x_sqr = np.linspace(0, 10, 100, dtype=np.float32)
# æ•°æ®é›†æ·»åŠ æ‰°åŠ¨
y_sqr = np.array([3*i**2 + 5 + random.random()*noise_2 for i in x_sqr], dtype=np.float32)

st.scatter_chart(pd.DataFrame({"x": x_sqr, "y":y_sqr}), x="x", y="y", size=scatter_size_2)


class DNNModel(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.input = nn.Linear(1,4)
        self.layers = nn.Sequential()
        for _ in range(2):
            self.layers.append(nn.Linear(4,4))
            self.layers.append(nn.ReLU())
        self.out = nn.Linear(4, 1)

    def forward(self, x):
        upper_dim_out = self.input(x)
        layer_out = self.layers(upper_dim_out)
        return self.out(layer_out)

dnn_model = DNNModel()



code_4 = """
# åˆ›å»ºæ¨¡å‹
class DNNModel(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.input = nn.Linear(1,4)
        self.layers = nn.Sequential()
        for _ in range(2):
            self.layers.append(nn.Linear(4,4))
            self.layers.append(nn.ReLU())
        self.out = nn.Linear(4, 1)

    def forward(self, x):
        upper_dim_out = self.input(x)
        layer_out = self.layers(upper_dim_out)
        return self.out(layer_out)
dnn_model = DNNModel()
print(dnn_model)

"""



code_6 = """
optimizer = torch.optim.Adam(params=[p for n, p in model.named_parameters()], 
                             lr=0.001)

epochs = 40
for epoch in range(epochs_2):
    for d, t in get_batch_data(list(zip(x_sqr, y_sqr)), 5, True):
        out = dnn_model(torch.unsqueeze(torch.tensor(d), dim=1))
        loss = torch.mean(torch.pow(out - torch.unsqueeze(torch.tensor(t),dim=1),2))
        loss_item.append(loss.item())
        # ä¼˜åŒ–å™¨æ¢¯åº¦æ¸…é™¤
        optimizer_2.zero_grad()
        # åå‘ä¼ æ’­
        loss.backward()
        # ä¼˜åŒ–æ›´æ–°
        optimizer_2.step()
"""
with st.expander("åˆ›å»ºæ¨¡å‹å¹¶è®­ç»ƒ"):
    st.write("éœ€è¦åˆ›å»ºæ›´åŠ å¤æ‚çš„æ¨¡å‹ï¼š")
    st.code(code_4, language='python')
    st.write("æ¨¡å‹ç»“æ„å¦‚ä¸‹ï¼š")
    st.text(dnn_model)
    st.code(code_3, language='python')

batch_size_2 = st.slider("batch", 1, 100, 20, key="batch_size_2")

# å­¦ä¹ ç‡
lr_2 = st.select_slider('learning_rate_b',options=[5e-5, 5e-4, 0.01, 0.02, 0.1, 0.2, 0.4], value=0.01, key="lr_2")

# epoch
epochs_2 = st.slider("epochs", 1, 200, 20, key="epochs_2")

# shuffle
shuffle_2 = st.toggle('æ‰“ä¹±æ•°æ®é›†', value=True, key="shuffle_2")

a_item = []
a_grad = []
loss_item = []
# ä¼˜åŒ–å™¨
optimizer_2 = torch.optim.Adam(params=[p for n, p in dnn_model.named_parameters()], lr=lr_2)


progress_text = "training... Please wait."
training_bar = st.progress(0, text=progress_text)


for epoch in range(epochs_2):
    for d, t in get_batch_data(list(zip(x_sqr, y_sqr)), batch_size_2, shuffle_2):
        out = dnn_model(torch.unsqueeze(torch.tensor(d), dim=1))

        loss = torch.mean(torch.pow(out - torch.unsqueeze(torch.tensor(t),dim=1),2))
        loss_item.append(loss.item())
        # ä¼˜åŒ–å™¨æ¢¯åº¦æ¸…é™¤
        optimizer_2.zero_grad()
        # åå‘ä¼ æ’­
        loss.backward()
        # a_grad.append(model.a.grad.item())
        # ä¼˜åŒ–æ›´æ–°
        optimizer_2.step()
        # a_item.append(model.a.item())
        
        training_bar.progress((epoch+1)/epochs_2, text=progress_text)
training_bar.empty()


st.line_chart(pd.DataFrame({"æŸå¤±å€¼loss": loss_item}), y="æŸå¤±å€¼loss")


final_text="""
### ç»“æŸè¯­
åœ¨çœŸæ­£ä½¿ç”¨æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦åƒä¸Šé¢ä¸€æ ·ï¼Œä¸€æ­¥æ­¥åˆ›å»ºæ¨¡å‹å—ï¼Ÿ

æ˜¯ä¸ç”¨çš„ï¼Œå½“å‰æœ‰å¾ˆå¤šå¼€æºç¤¾åŒºï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„æ‹¿åˆ°ä¸€äº›æ¨¡å‹ã€‚

æ¯”å¦‚å¼€æºç¤¾åŒº[ğŸ¤— Tokenizersåº“](https://huggingface.co/) å’Œ [ğŸ¤– ModelScope](https://modelscope.cn/models)

"""


st.markdown(final_text)

